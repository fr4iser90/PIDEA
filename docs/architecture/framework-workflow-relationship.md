# Framework vs Workflow Relationship

## âŒ **Falsche Vorstellung:**
```
Workflow â†’ Framework â†’ Step
```

## âœ… **Korrekte Architektur:**
```
Workflow â†’ Step â†’ Framework
```

## ðŸ”„ **Detaillierte Beziehung**

```mermaid
graph TB
    subgraph "Workflows (Ebene 1)"
        WF1[system_health_check.yaml]
        WF2[code_generation.yaml]
        WF3[deployment.yaml]
    end
    
    subgraph "Steps (Ebene 0)"
        S1[check_container_status]
        S2[check_gpu_usage]
        S3[generate_response]
        S4[apply_config]
        S5[run_tests]
        S6[deploy_container]
    end
    
    subgraph "Frameworks (Tools/Libraries)"
        F1[docker_engine]
        F2[monitor_agent]
        F3[ai_service]
        F4[config_manager]
        F5[test_runner]
        F6[deployment_service]
    end
    
    %% Workflows verwenden Steps
    WF1 --> S1
    WF1 --> S2
    WF2 --> S3
    WF2 --> S4
    WF3 --> S5
    WF3 --> S6
    
    %% Steps nutzen Frameworks
    S1 --> F1
    S2 --> F2
    S3 --> F3
    S4 --> F4
    S5 --> F5
    S6 --> F6
```

## ðŸ“ **Struktur in der Praxis**

```
automation-platform/
â”œâ”€â”€ workflows/                    # Definiert ABLÃ„UFE
â”‚   â”œâ”€â”€ analyze/
â”‚   â”‚   â””â”€â”€ system_health.yaml   # Workflow-Definition
â”‚   â””â”€â”€ deploy/
â”‚       â””â”€â”€ app_stack.yaml       # Workflow-Definition
â”œâ”€â”€ steps/                       # Einzelne Aktionen
â”‚   â”œâ”€â”€ check_container_status.py
â”‚   â”œâ”€â”€ check_gpu_usage.py
â”‚   â”œâ”€â”€ generate_response.py
â”‚   â””â”€â”€ apply_config.py
â””â”€â”€ frameworks/                  # WerkzeugkÃ¤sten
    â”œâ”€â”€ docker_engine/
    â”‚   â””â”€â”€ container_manager.py
    â”œâ”€â”€ monitor_agent/
    â”‚   â””â”€â”€ system_monitor.py
    â”œâ”€â”€ ai_service/
    â”‚   â””â”€â”€ llm_client.py
    â””â”€â”€ config_manager/
        â””â”€â”€ config_handler.py
```

## ðŸ”§ **Konkrete Beispiele**

### 1. Workflow Definition (`system_health.yaml`)
```yaml
name: system_health_check
category: analyze
steps:
  - check_container_status
  - check_gpu_usage
  - log_results
```

### 2. Step Implementation (`check_container_status.py`)
```python
from frameworks.docker_engine.container_manager import ContainerManager

def check_container_status():
    # Step nutzt Framework
    container_manager = ContainerManager()
    status = container_manager.get_status("my-app")
    return {"status": status, "timestamp": datetime.now()}
```

### 3. Framework Implementation (`container_manager.py`)
```python
class ContainerManager:
    def get_status(self, container_name):
        # Framework-Logik
        return subprocess.run(["docker", "ps", "-q", "-f", f"name={container_name}"])
```

## ðŸŽ¯ **Warum diese Trennung?**

### **Workflows sind "dumm"**
- Definieren nur die Reihenfolge
- Wissen nicht, WIE etwas gemacht wird
- Sind wiederverwendbar

### **Steps sind "schlau"**
- Wissen, WELCHE Frameworks sie brauchen
- FÃ¼hren konkrete Aktionen aus
- Sind wiederverwendbar

### **Frameworks sind "Werkzeuge"**
- Enthalten die eigentliche Logik
- Sind wiederverwendbar
- KÃ¶nnen von verschiedenen Steps genutzt werden

## ðŸ”„ **Wiederverwendbarkeit**

```mermaid
graph LR
    subgraph "Workflow A"
        WA[deploy_app.yaml]
    end
    
    subgraph "Workflow B"
        WB[health_check.yaml]
    end
    
    subgraph "Gemeinsame Steps"
        S1[check_container_status]
        S2[apply_config]
    end
    
    subgraph "Gemeinsame Frameworks"
        F1[docker_engine]
        F2[config_manager]
    end
    
    WA --> S1
    WA --> S2
    WB --> S1
    
    S1 --> F1
    S2 --> F2
```

## âœ… **Zusammenfassung**

1. **Workflows** = "Was soll gemacht werden?" (Reihenfolge)
2. **Steps** = "Wie wird es gemacht?" (Aktionen)
3. **Frameworks** = "Womit wird es gemacht?" (Werkzeuge)

**Du brauchst alle drei Ebenen:**
- Workflows fÃ¼r die Orchestrierung
- Steps fÃ¼r die Wiederverwendbarkeit
- Frameworks fÃ¼r die ModularitÃ¤t

Diese Trennung macht dein System maximal flexibel und skalierbar! ðŸš€ 